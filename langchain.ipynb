{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# import os\n",
    "# print(os.getenv('REQUESTS_CA_BUNDLE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing OpenAI LLM model using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature (ranges b/w 0 and 1) : how creative we want our model to be.  \n",
    "\n",
    "0 -> it means model is very safe it is not taking any bets. (The more closer it is towards 0, the outputs will tend to be more or less the same for same prompt)  \n",
    "\n",
    "1 -> It will take risk it might generate wrong output but it is very creative. (The more closer it is towards 1, the more creative liberty it takes which may give diverse responses if we run same prompt multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of China is Beijing.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of China\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Huggingface Open-Source LLM model using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naushads/Documents/jupyter_notebooks/langchain-demo/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naushads/Documents/jupyter_notebooks/langchain-demo/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_hf = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":64}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "print(llm_hf.predict(\"Can you tell me the capital of Russia?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates and Langchain LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me the capital of India'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "country_capital_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Can you tell me the capital of {country}\"\n",
    ")\n",
    "country_capital_prompt_template.format(country=\"India\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm_country_capital_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=country_capital_prompt_template\n",
    ")\n",
    "print(llm_country_capital_chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai\n"
     ]
    }
   ],
   "source": [
    "llm_hf_country_capital_chain = LLMChain(\n",
    "    llm=llm_hf, \n",
    "    prompt=country_capital_prompt_template\n",
    ")\n",
    "print(llm_hf_country_capital_chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_capital_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Can you tell me the capital of {country}\"\n",
    ")\n",
    "\n",
    "llm_country_capital_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=country_capital_prompt_template\n",
    ")\n",
    "\n",
    "famous_places_in_capital_city_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in {capital}\"\n",
    ")\n",
    "\n",
    "llm_famous_places_in_capital_city_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=famous_places_in_capital_city_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This city is a great mix of modern and ancient India. With its many monuments, temples, and galleries, it is a must-see for any traveler. Other places to visit in India include:\n",
      "\n",
      "1. Taj Mahal, Agra: One of the world's most iconic monuments, the Taj Mahal is a symbol of love and beauty.\n",
      "\n",
      "2. Jaipur: The \"Pink City\" of Rajasthan, Jaipur is a vibrant city known for its forts, palaces, and bazaars.\n",
      "\n",
      "3. Goa: A popular beach destination, Goa has stunning beaches and a lively nightlife.\n",
      "\n",
      "4. Kerala: Nicknamed \"God's Own Country,\" Kerala is known for its lush green landscapes, traditional villages, and backwaters.\n",
      "\n",
      "5. Varanasi: One of the holiest cities in India, Varanasi is a must-visit for its ancient temples, ghats, and spiritual atmosphere.\n",
      "\n",
      "6. Leh-Ladakh: Located in the Himalayas, this mountain region is known for its rugged beauty, monasteries, and adventure activities.\n",
      "\n",
      "7. Andaman & Nicobar Islands: These tropical islands offer stunning beaches, crystal clear\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "famous_places_in_capital_city_chain = SimpleSequentialChain(\n",
    "    chains=[\n",
    "        llm_country_capital_chain, \n",
    "        llm_famous_places_in_capital_city_chain\n",
    "    ]\n",
    ")\n",
    "print(famous_places_in_capital_city_chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_capital_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"Can you tell me the capital of {country}\"\n",
    ")\n",
    "\n",
    "llm_country_capital_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=country_capital_prompt_template,\n",
    "    output_key=\"capital\"\n",
    ")\n",
    "\n",
    "famous_places_in_capital_city_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"capital\"],\n",
    "    template=\"Suggest me some amazing places to visit in {capital}\"\n",
    ")\n",
    "\n",
    "llm_famous_places_in_capital_city_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=famous_places_in_capital_city_prompt_template,\n",
    "    output_key=\"places\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(\n",
    "    chains=[\n",
    "        llm_country_capital_chain,\n",
    "        llm_famous_places_in_capital_city_chain\n",
    "    ],\n",
    "    input_variables=[\n",
    "        \"country\"\n",
    "    ],\n",
    "    output_variables=[\n",
    "        \"capital\",\n",
    "        \"places\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'India', 'capital': '\\n\\nThe capital of India is New Delhi.', 'places': \" Here are some amazing places to visit in New Delhi: \\n\\n1. Red Fort: This iconic fort in the heart of the city is a must-see. It was built in the 17th century and is a great example of Mughal architecture. \\n\\n2. India Gate: This imposing structure is a memorial to the martyrs of World War I and a popular tourist spot. \\n\\n3. Jama Masjid: One of the largest mosques in India, Jama Masjid is a beautiful sight. It was built in the 17th century by Mughal Emperor Shah Jahan. \\n\\n4. Humayun's Tomb: This is a UNESCO World Heritage Site and a great example of Mughal architecture. It was built in the 16th century and is the tomb of the Mughal Emperor Humayun. \\n\\n5. Qutub Minar: This is one of the oldest and tallest minarets in India. It was built in the 13th century and is a great example of Indo-Islamic architecture. \\n\\n6. Lotus Temple: This is a stunning architectural marvel and a popular tourist destination. It was built in the 20th century and is a great place to relax and med\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\n",
    "    chain(\n",
    "        {\n",
    "            \"country\":\"India\"\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat models using ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chatllm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Artificial intelligence is great, until it starts sending you passive-aggressive error messages like \\'Did you really think that was a good idea?\\'\"\\n2. \"They say AI is the future, but I\\'m still waiting for a robot chef that can actually make a decent sandwich.\"\\n3. \"AI can do a lot of things, but can it make your ex\\'s new relationship status magically disappear from your Facebook feed? Asking for a friend.\"\\n4. \"I asked Siri if she believes in love at first sight. She responded, \\'I\\'m sorry, I can\\'t answer that. But I can search the web for you.\\' Thanks for nothing, Siri.\"\\n5. \"They say AI is getting smarter every day, but I still can\\'t get my virtual assistant to understand my mom\\'s voicemail instructions.\"\\n6. \"I tried talking to my smart speaker, but it just started playing \\'Baby Shark\\' on repeat. I think it\\'s trying to drive me insane.\"\\n7. \"I asked Alexa if she had any dating advice for me. She said, \\'Just be yourself.\\' Thanks, Alexa, I guess even AI knows I\\'m doomed.\"\\n8. \"AI is supposed to make our lives easier, but I swear my virtual assistant has a vendetta against me. It\\'s always \\'Sorry, I didn\\'t quite get that\\' when I ask for help.\"\\n9. \"They say AI can analyze your personality based on your online activity. Well, if my AI profile is accurate, I\\'m apparently a combination of a cat video addict and a professional procrastinator.\"\\n10. \"I asked my AI assistant for a joke, and it said, \\'Why don\\'t scientists trust atoms? Because they make up everything!\\' Well played, AI, well played.\"')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "chatllm([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(\n",
    "    temperature=0.6,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeperatedOutput(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatmodel_system_message_template = \"You are a helpful assistant. \\\n",
    "    When the user gives any input word, you should generate 5 synonyms of the input word \\\n",
    "    in a comma seperated manner.\"\n",
    "chatmodel_human_message_template = \"{text}\"\n",
    "\n",
    "chatprompt = ChatPromptTemplate.from_messages({\n",
    "    (\"system\", chatmodel_system_message_template),\n",
    "    (\"human\", chatmodel_human_message_template)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure! Please provide a word for which you would like to generate synonyms.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chatprompt | chatllm | CommaSeperatedOutput()\n",
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
